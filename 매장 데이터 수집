# -*- coding: utf-8 -*-
"""GS留ㅼ옣�뺣낫.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NcbLZSMTyHqWWyUrQMGRn0-z8dJBEYX2
"""

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
import time
from selenium.webdriver import Keys
import pandas as pd

chrome_options = webdriver.ChromeOptions()
chrome_options.add_experimental_option('detach',True)
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()),options=chrome_options)

driver.maximize_window()

driver.get('http://gs25.gsretail.com/gscvs/en/store-services/locations#;')
time.sleep(5)

driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.PAGE_DOWN)
time.sleep(1)

data_list = []
while True:
    driver.find_element(By.XPATH,'//*[@id="pagingTagBox"]/a[2]').click()
    time.sleep(1)

    data1 = driver.find_elements(By.XPATH,'//*[@id="storeInfoList"]/tr[1]/td[2]/a')
    data2 = driver.find_elements(By.XPATH,'//*[@id="storeInfoList"]/tr[2]/td[2]/a')
    data3 = driver.find_elements(By.XPATH,'//*[@id="storeInfoList"]/tr[3]/td[2]/a')
    data4 = driver.find_elements(By.XPATH,'//*[@id="storeInfoList"]/tr[4]/td[2]/a')
    data5 = driver.find_elements(By.XPATH,'//*[@id="storeInfoList"]/tr[5]/td[2]/a')
    time.sleep(1)
    data_list = []

    for data in [data1, data2, data3, data4, data5]:
        for element in data:
            print(element.text)
            data_list.append(element.text.strip())
    if '�쒖슱 �깅룞援� �뺤떗由щ줈20湲�8 (�꾩꽑�� 29, �쒖쁺鍮뚮뵫)' in data_list:
        break

df = pd.DataFrame({'�볤�':data_list})
df.to_csv('GS留ㅼ옣.csv')
